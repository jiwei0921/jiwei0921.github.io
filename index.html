<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="UTF-8">
  <title>Wei Ji</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<head>
    <style>
        .video-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: space-between;
        }
        .video {
            width: 48%; 
        }
        .caption {
            text-align: center;
            font-weight: bold;
        }
        .text {
            text-align: left;
        }
    </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wei Ji</name>
              </p>
              <p>
                I am a final-year PhD student in Computer Engineering at University of Alberta, advised by <a href="https://www.ece.ualberta.ca/~lcheng5/">Prof. Li Cheng</a> in VLLab. 
                I have worked at Samsung Research America, ByteDance, and Tencent.
                <!-- 
                I am a PostDoc at Yale University. 
                I received my PhD degree in Computer Engineering at University of Alberta, 
                and worked as a visiting PhD student at Johns Hopkins University. 
                I have also spent great time at Samsung Research America, ByteDance and Tencent.
                 -->
              </p>
              <p>
                My research lies in the fundamental aspects of Computer Vision, particularly in the areas of detection, segmentation, and multi-modal robust learning. My goal is to build intelligent visual perception systems capable of accurately modeling scene representation and widely applying to real-world scenarios. 
                <!-- Application cases of my work include medical diagnosis systems, robot obstacle avoidance, safer autonomous vehicles, and portrait editor tools. -->
              </p>
              <p>
                <em>"Open Your Mind to More Possibilities."</em>
              </p>
              <p style="text-align:center">
                <a href="mailto:wji3@ualberta.ca">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=G4uCKHcAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/jiwei0921/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:27%;max-width:27%">
              <a href="images/wei.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/wei.png" class="hoverZoomLink"></a> 
            </td>
          </tr>
       

        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Recent News</heading>
            <ul>
                <li>Two papers are accepted by <em>AAAI</em> 2024.</li> 
                <li>One paper is accepted by <em>NeurIPS</em> 2023.</li>  
                <li>One paper is accepted by <em>ICCV</em> 2023.</li>
                <li>One paper is accepted by <em>ACM Multimedia</em> 2023.</li> 
                <li>Our paper is selected as <b>Best Paper</b> on <em>VISION</em> workshop at <em>CVPR</em> 2023.</li>
                <li>One paper is accepted by <em>CVPR</em> 2023.</li>
                <li>Awarded the Alberta Innovates Graduate Student Scholarship.</li>
                <!--<li>Passed my Ph.D. Candidacy Oral exam.</li> 
                <li>Achieved the J Gordin Kaplan Graduate Student Award.</li>  -->
                <!--<li>One paper is accepted by <b>IJCV</b>.</li>
                <li>Achieved the Floyd Derkat Graduate Award in Artificial Intelligence and Machine Learning.</li>
                <li>Two papers are accepted by <b>ICLR 2022</b> and <b>CVPR 2022</b>.</li> -->
                . . .
              </div>
            </ul>
          </td>
        </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
	            <p>
                <a href="https://scholar.google.com/citations?user=G4uCKHcAAAAJ">Full list of publised papers &#8594;</a>
                </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    


          <tr onmouseout="SegDiff_stop()" onmouseover="SegDiff_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='MedSegDiff_image'>
                    <img src='images/MedSegDiff.gif' width="160"></div>
                  <img src='images/MedSegDiff.gif' width="160">
                </div>
                <script type="text/javascript">
                  function SegDiff_start() {
                    document.getElementById('MedSegDiff_image').style.opacity = "1";
                  }
  
                  function SegDiff_stop() {
                    document.getElementById('MedSegDiff_image').style.opacity = "0";
                  }
                  SegDiff_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/pdf/2301.11798.pdf">
                  <papertitle>MedSegDiff-V2: Diffusion meets Transformer for Accurate Medical Image Segmentation</papertitle>
                </a>
                <br>
                Junde Wu, <strong>Wei Ji</strong>,
                Huazhu Fu, Min Xu, Yueming Jin, Yanwu Xu
                <br>
                <em>AAAI</em>, 2024
                <br>
                <a href="https://arxiv.org/pdf/2301.11798.pdf">paper</a>
                  /
                  <a href="https://github.com/KidsWithTokens/MedSegDiff">code repository</a>
                <p></p>
                <p>
                    We introduce MedSegDiff-V2, which features two conditioning techniques. This innovation minimizes diffusion variance in segmentation, enhancing prediction calibration. 
                    To our knowledge, it is the first to integrate transformer into a diffusion-based model for general medical image segmentation. 
                    Extensive experiments on 20 medical image segmentation tasks verify its effectiveness.
                  </p>
              </td>
            </tr>


          <tr onmouseout="MVSS_stop()" onmouseover="MVSS_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='MVSS_image'>
                  <img src='images/MVSS_before.png' width="160"></div>
                <img src='images/MVSS_after.png' width="160">
              </div>
              <script type="text/javascript">
                function MVSS_start() {
                  document.getElementById('MVSS_image').style.opacity = "1";
                }

                function MVSS_stop() {
                  document.getElementById('MVSS_image').style.opacity = "0";
                }
                MVSS_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Multispectral_Video_Semantic_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2023_paper.pdf">
                <papertitle>Multispectral Video Semantic Segmentation: A Benchmark Dataset and Baseline</papertitle>
              </a>
              <br>
              <strong>Wei Ji</strong>,
              Jingjing Li, Cheng Bian, Zongwei Zhou, Jiaying Zhao, Alan Yuille, Li Cheng
              <br>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Multispectral_Video_Semantic_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2023_paper.pdf">paper</a>
               /
               <a href="https://jiwei0921.github.io/Multispectral-Video-Semantic-Segmentation/">project website</a>
              <p></p>
              <p>
                  We set out to address a promising new task of semantic segmentation of multispectral video input, i.e., MVSS. To this end, an in-house MVSeg benchmark dataset and a dedicated baseline are curated and developed. This is expected to serve as a good starting point for future advancements in the MVSS task.
              </p>
            </td>
          </tr>


            <tr onmouseout="SAM_stop()" onmouseover="SAM_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='SAM_image'>
                    <img src='images/SAM_after.png' width="160"></div>
                  <img src='images/SAM_before.png' width="160">
                </div>
                <script type="text/javascript">
                  function SAM_start() {
                    document.getElementById('SAM_image').style.opacity = "1";
                  }
  
                  function SAM_stop() {
                    document.getElementById('SAM_image').style.opacity = "0";
                  }
                  SAM_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2304.05750">
                  <papertitle>Segment Anything Is Not Always Perfect: An Investigation of SAM on Different Real-World Applications</papertitle>
                </a>
                <br>
                <strong>Wei Ji</strong>,
                Jingjing Li, Qi Bi, Tingwei Liu, Wenbo Li, Li Cheng
                <br>
                <em>CVPR Workshop</em>, 2023 &nbsp <font color="red"><strong>(Best Paper)</strong></font>
                <br>
                <em>Machine Intelligence Research</em>, Long Version
                <br>
                 <a href="https://arxiv.org/abs/2304.05750">paper</a>
                 /
                 <a href="https://github.com/LiuTingWed/SAM-Not-Perfect">code repository</a>
                <p></p>
                <p>
                  We conduct a series of intriguing investigations into the performance of SAM across various applications, particularly in the fields of natural images, agriculture, manufacturing, remote sensing, and healthcare. We analyze and discuss the benefits and limitations of SAM and provide an outlook on future development of segmentation tasks.
                </p>
              </td>
            </tr>



            <tr onmouseout="MedSAM_stop()" onmouseover="MedSAM_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='MedSAM_image'>
                      <img src='images/MedSAM_after.png' width="160"></div>
                    <img src='images/MedSAM_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function MedSAM_start() {
                      document.getElementById('MedSAM_image').style.opacity = "1";
                    }
    
                    function MedSAM_stop() {
                      document.getElementById('MedSAM_image').style.opacity = "0";
                    }
                    MedSAM_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2304.12620.pdf">
                    <papertitle>Medical SAM Adapter: Adapting Segment Anything Model for Medical Image Segmentation</papertitle>
                  </a>
                  <br>
                  Junde Wu, <strong>Wei Ji</strong>,
                  Yuanpei Liu, Huazhu Fu, Min Xu, Yanwu Xu, Yueming Jin
                  <br>
                  <em>arXiv preprint</em>, 2023  
                  <br>
                   <a href="https://arxiv.org/pdf/2304.12620.pdf">paper</a>
                   /
                   <a href="https://github.com/KidsWithTokens/Medical-SAM-Adapter">code repository</a>
                  <p></p>
                  <p>
                      We present the Medical SAM Adapter (Med-SA), which incorporates domain-specific medical knowledge into powerful SAM through the proposed SD-Trans and HyP-Adpt in a light yet effective adaptation way. 
                      Experiments show that our Med-SA achieves remarkable performance across 17 medical image segmentation tasks, surpassing state-of-the-art methods while modifying just 2% of the parameters. 
                  </p>
                </td>
              </tr>


          
            <tr onmouseout="DSU_stop()" onmouseover="DSU_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='DSU_image'>
                      <img src='images/DSU_after.png' width="160"></div>
                    <img src='images/DSU_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function DSU_start() {
                      document.getElementById('DSU_image').style.opacity = "1";
                    }
    
                    function DSU_stop() {
                      document.getElementById('DSU_image').style.opacity = "0";
                    }
                    DSU_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2205.07179.pdf">
                    <papertitle>Promoting Saliency From Depth: Deep Unsupervised RGB-D Saliency Detection</papertitle>
                  </a>
                  <br>
                  <strong>Wei Ji</strong>,
                  Jingjing Li, Qi Bi, Chuan Guo, Jie Liu, Li Cheng
                  <br>
                  <em>ICLR</em>, 2022
                  <br>
                   <a href="https://arxiv.org/pdf/2205.07179.pdf">paper</a>
                   /
                   <a href="https://github.com/jiwei0921/DSU/">code repository</a>
                  <p></p>
                  <p>
                      We tackle the new task of deep unsupervised RGB-D saliency detection, where depth information is internally engaged and refined to capture trustworthy supervision signals without introducing human efforts.
                  </p>
                </td>
              </tr>



            <tr onmouseout="ML3D_stop()" onmouseover="ML3D_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='3D_image'>
                    <img src='images/3D_after.png' width="160"></div>
                  <img src='images/3D_before.png' width="160">
                </div>
                <script type="text/javascript">
                  function ML3D_start() {
                    document.getElementById('3D_image').style.opacity = "1";
                  }
  
                  function ML3D_stop() {
                    document.getElementById('3D_image').style.opacity = "0";
                  }
                  ML3D_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.pdf">
                  <papertitle>Generating Diverse and Natural 3D Human Motions From Text</papertitle>
                </a>
                <br>
                Chuan Guo, Shihao Zou, Xinxin Zuo, Sen Wang, 
                <strong>Wei Ji</strong>,
                Xingyu Li, Li Cheng
                <br>
                <em>CVPR</em>, 2022
                <br>
                 <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.pdf">paper</a>
                 /
                 <a href="https://ericguo5513.github.io/text-to-motion/">project website</a>
                <p></p>
                <p>
                  We propose using motion snippet code as an internal representation of human motions from text, improving the generation of realistic motions aligned with the input. Furthermore, we introduce the HumanML3D dataset, consisting of 14,616 motion clips and 44,970 text descriptions, to support further advancements in this area.                </p>
              </td>
            </tr>


              <tr onmouseout="MR_stop()" onmouseover="MR_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='MR_image'>
                      <img src='images/MR_after.png' width="160"></div>
                    <img src='images/MR_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function MR_start() {
                      document.getElementById('MR_image').style.opacity = "1";
                    }
    
                    function MR_stop() {
                      document.getElementById('MR_image').style.opacity = "0";
                    }
                    MR_stop()
                  </script>
                </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf">
                <papertitle>Learning Calibrated Medical Image Segmentation via Multi-Rater Agreement Modeling</papertitle>
              </a>
              <br>
              <strong>Wei Ji</strong>,
              Shuang Yu, Junde Wu, Kai Ma, Cheng Bian, Qi Bi, Jingjing Li,
              Hanruo Liu, Li Cheng, Yefeng Zheng
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Best Paper Candidate)</strong></font>
              <br>
               <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf">paper</a>
               /
               <a href="https://github.com/jiwei0921/MRNet/">code repository</a>
              <p></p>
              <p>
                We propose to explicitly model the multi-rater agreement regarding medical images, where it integrates varied expertise-level of individual raters, and can produce corresponding calibrated predictions that better reflect the underlying graders‚Äô (dis-)agreement.
              </p>
            </td>
          </tr>		

          
          <tr onmouseout="DCF_stop()" onmouseover="DCF_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='DCF_image'>
                  <img src='images/DCF_after.png' width="160"></div>
                <img src='images/DCF_before.png' width="160">
              </div>
              <script type="text/javascript">
                function DCF_start() {
                  document.getElementById('DCF_image').style.opacity = "1";
                }

                function DCF_stop() {
                  document.getElementById('DCF_image').style.opacity = "0";
                }
                DCF_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Calibrated_RGB-D_Salient_Object_Detection_CVPR_2021_paper.pdf">
                <papertitle>Calibrated RGB-D Salient Object Detection</papertitle>
              </a>
              <br>
              <strong>Wei Ji</strong>,
              Jingjing Li, Shuang Yu, Miao Zhang, Yongri Piao, Shunyu Yao, Qi Bi, Yefeng Zheng, Huchuan Lu, Li Cheng
              <br>
              <em>CVPR</em>, 2021 &nbsp (Extended to IJCV)
              <br>
               <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Calibrated_RGB-D_Salient_Object_Detection_CVPR_2021_paper.pdf">paper</a>
               /
               <a href="https://link.springer.com/article/10.1007/s11263-022-01734-1">long version</a>
               /
               <a href="https://github.com/jiwei0921/DCF">code repository</a>
              <p></p>
              <p>
                We propose a Depth Calibration and Fusion (DCF) method, which is able to correct the latent bias in the original depth maps, and generate an optimal calibration of the depth values that directly promotes detection accuracy. Its effectiveness and scalability are demonstrated with extensive experiments on five public benchmarks. </p>
            </td>
          </tr>
        


            <tr onmouseout="CAT_stop()" onmouseover="CAT_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cat_image'>
                  <img src='images/cat_after.png' width="160"></div>
                <img src='images/cat_before.png' width="160">
              </div>
              <script type="text/javascript">
                function CAT_start() {
                  document.getElementById('cat_image').style.opacity = "1";
                }

                function CAT_stop() {
                  document.getElementById('cat_image').style.opacity = "0";
                }
                CAT_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://proceedings.neurips.cc/paper/2021/file/642e92efb79421734881b53e1e1b18b6-Paper.pdf">
                <papertitle>Joint Semantic Mining for Weakly Supervised RGB-D Salient Object Detection</papertitle>
              </a>
              <br>
              Jingjing Li, <strong>Wei Ji</strong>,
              Qi Bi, Cheng Yan, Miao Zhang, Yongri Piao, Huchuan Lu, Li Cheng
              <br>
              <em>NeurIPS</em>, 2021
              <br>
               <a href="https://proceedings.neurips.cc/paper/2021/file/642e92efb79421734881b53e1e1b18b6-Paper.pdf">paper</a>
               /
               <a href="https://github.com/jiwei0921/JSM">code repository</a>
              <p></p>
              <p>
                We attempt to tackle the new problem of weakly-supervised RGB-D salient object detection, where low-cost spatial and textual semantics are used to provide trustworthy training signals. Our framework is flexible and can be easily adapted to other fully-/un-supervised settings.
              </p>
            </td>
          </tr>


          <tr onmouseout="MICCAI_stop()" onmouseover="MICCAI_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='micca_image'>
                  <img src='images/miccai_after.png' width="160"></div>
                <img src='images/miccai_before.png' width="160">
              </div>
              <script type="text/javascript">
                function MICCAI_start() {
                  document.getElementById('micca_image').style.opacity = "1";
                }

                function MICCAI_stop() {
                  document.getElementById('micca_image').style.opacity = "0";
                }
                MICCAI_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_6">
                <papertitle>Local-Global Dual Perception Based Deep Multiple Instance Learning for Retinal Disease Classification</papertitle>
              </a>
              <br>
              Qi Bi, Shuang Yu, <strong>Wei Ji</strong>,
              Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng
              <br>
              <em>MICCAI</em>, 2021 &nbsp <font color="red"><strong>(Young Scientist Award Nomination)</strong></font>
              <br>
               <a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_6">paper</a>
               /
               <a href="https://miccai2021.org/openaccess/paperlinks/2021/09/01/294-Paper0778.html">open reviews</a>
              <p></p>
              <p>
                We propose an effective deep multiple instance learning framework that integrates the instance contribution from both local and global scales. It has been demonstrated to be scalable and versatile across different CNNs and medical tasks.
              </p>
            </td>
          </tr>


          <tr onmouseout="ECCV_stop()" onmouseover="ECCV_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ECCV_image'>
                  <img src='images/conet_after.png' width="160"></div>
                <img src='images/conet_before.png' width="160">
              </div>
              <script type="text/javascript">
                function ECCV_start() {
                  document.getElementById('ECCV_image').style.opacity = "1";
                }

                function ECCV_stop() {
                  document.getElementById('ECCV_image').style.opacity = "0";
                }
                ECCV_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2007.11782.pdf">
                <papertitle>Accurate RGB-D Salient Object Detection via Collaborative Learning</papertitle>
              </a>
              <br>
              <strong>Wei Ji</strong>,
              Jingjing Li, Miao Zhang, Yongri Piao, Huchuan Lu
              <br>
              <em>ECCV</em>, 2020
              <br>
               <a href="https://arxiv.org/pdf/2007.11782.pdf">paper</a>
               /
               <a href="https://github.com/jiwei0921/CoNet/">code repository</a>
              <p></p>
              <p>
                We introduce a collaborative learning scheme where three mutual-benefit tasks (saliency, depth, and edge) work together to improve internal characteristics. This results in accurate detection with sharp boundaries and faster speeds, while avoiding extra depth input during inference.
              </p>
            </td>
          </tr>


          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mira_image'>
                  <img src='images/mira_after.png' width="160"></div>
                <img src='images/mira_before.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9729103">
                <papertitle>Depth-induced Multi-scale Recurrent Attention Network for Saliency Detection</papertitle>
              </a>
              <br>
              <strong>Wei Ji</strong>,
              Ge Yan, Jingjing Li, Yongri Piao, Miao Zhang, Li Cheng, Huchuan Lu
              <br>
              <em>ICCV</em>, 2019 &nbsp (Extended to IEEE TIP, &nbsp <font color="red"><strong>Popular Article</strong></font>)
              <br>
               <a href="https://ieeexplore.ieee.org/abstract/document/9729103">long version</a>
               /
               <a href="https://github.com/jiwei0921/DMRA">code repository</a>
              <p></p>
              <p>
                We propose a novel attention mechanism that can progressively optimize local details with memory-oriented scene understanding for generating appealing results. Its effectiveness is demonstrated on nine public benchmark datasets.
              </p>
            </td>
          </tr>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Application Examples</heading>
                <p>
                    I do my best towards engaging in valuable research that is <em>insightful</em>, <em>impactful</em>, or, at the very least, <em>highly practical</em>. Please find examples of its applications below.
                </p>
              </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <body>
                <div class="video-container">
                    <div class="video">
                        <video width="100%" controls autoplay loop>
                            <source src="videos/apple_SOD.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <div class="caption">Class-Agnostic Salient Object Segmentation</div>
                        <div class="text"><a href="https://machinelearning.apple.com/research/salient-object-segmentation">This task</a> 
                          is characterized by a class-agnostic nature, which is different from semantic segmentation with a fixed set of categories. 
                          It enables the handling of diverse and arbitrary objects, making it essential for augmented reality (AR) applications like object highlight, and target extraction.
                          
                        </div>
                    </div>
                    <div class="video">
                        <video width="100%" controls autoplay loop>
                            <source src="videos/background.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <div class="caption">Background Removal/Substitution</div>
                        <div class="text">
                            <a href="https://github.com/renatoviolin/bg-remove-augment">This task</a> 
                            is capable of separating the foreground object from its original background and replacing it with an alternative backdrop, 
                            offering users the ability to customize their virtual surroundings. 
                            Its application cases involve video conferencing and image editing. 
                            
                        </div>
                    </div>
                </div>
            </body>
          </td>
          </tr>
          <tr>
            <td>
              <body>
                <div class="video-container">
                    <div class="video">
                        <video width="100%" controls autoplay loop>
                            <source src="videos/MVSS.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <div class="caption">Perception of Complex Scene</div>
                        <div class="text">
                            <a href="https://jiwei0921.github.io/Multispectral-Video-Semantic-Segmentation/">This task</a> 
                            involves understanding and parsing objects, regions, and their relationships in images or video frames, especially in complex or low-light scenarios.
                            This enhances model's robustness in applications like autonomous driving and nighttime patrols. 
                            
                        </div>
                    </div>
                    <div class="video">
                        <video width="100%" controls autoplay loop>
                            <source src="videos/PolyP.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <div class="caption">Diagnosis of Medical Lesion</div>
                        <div class="text">
                          Medical image segmentation (e.g., <a href="https://link.springer.com/chapter/10.1007/978-3-030-87193-2_14">polyp</a>) assists in outlining abnormalities or lesions areas within the body, ensuring accurate treatment delivery and minimizing damage to healthy tissue.
                          Typically, it can aid in diagnosing conditions like tumors and organ diseases.
                          
                        </div>
                    </div>
                </div>
            </body>
          </td>
          </tr>
        </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
              <td width="100%" valign="middle">
                  <heading>Selected Awards</heading>
                  <!-- <br /> -->
              <ul>
                <li>Best Paper (Most Insightful Paper), <em>VISION</em> Workshop at CVPR, 2023</li>
                <li>J Gordin Kaplan Graduate Student Award ($1,500CAD), 2023</li>
                <li>Alberta Innovates Graduate Student Scholarship ($62,000CAD), 2023</li>
                <li>Floyd Derkat Graduate Award in Artificial Intelligence and Machine Learning ($5,000CAD), 2022</li>
                <li>Best Paper Candidate, CVPR, 2021</li>
                <li>Young Scientist Award Nomination, MICCAI, 2021</li>
                <li>Rank 1st in the leaderboard of QUBIQ Challenge at MICCAI, 2020</li>
              </ul>
            <!--
              <ul>
                <li>Distinguished Graduate Thesis of Dalian University of Technology, 2019</li>
              </ul>
              <ul>
                <li>National First Prize of `China Graduate Contest on Application, Design and Innovation of Mobile-Terminal`, 2017</li>
              </ul> 
              -->   
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Modified from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
